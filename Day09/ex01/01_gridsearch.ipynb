{"cells":[{"cell_type":"markdown","metadata":{"id":"gJm_8nRDyUp7"},"source":["# Day 09. Exercise 01\n","# Gridsearch"]},{"cell_type":"markdown","metadata":{"id":"OLB1I9UiyUp-"},"source":["## 0. Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rjrDzFRzyUp_"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from tqdm.notebook import tqdm\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import ParameterGrid, GridSearchCV\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"markdown","metadata":{"id":"F8zodjDJyUqA"},"source":["## 1. Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"PWR10A1TyUqA"},"source":["1. Read the file [`day-of-week-not-scaled.csv`](https://drive.google.com/file/d/1AlGvsJDSzPT_70caausx8bFuupIEZkfh/view?usp=sharing). It is similar to the one from the previous exercise, but this time we did not scale continuous features (we are not going to use logreg anymore).\n","2. Using `train_test_split` with parameters `test_size=0.2`, `random_state=21` get `X_train`, `y_train`, `X_test`, `y_test`. Use the additional parameter `stratify`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c8RWKHJbyUqA"},"outputs":[],"source":["df = pd.read_csv('../data/day-of-week-not-scaled.csv')\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D5f4G8reyUqB"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(\n","    df.drop('dayofweek', axis=1), df['dayofweek'],\n","    test_size=0.2, random_state=21, stratify=df['dayofweek']\n","    )"]},{"cell_type":"markdown","metadata":{"id":"Qx6PXWY3yUqB"},"source":["## 2. SVM gridsearch"]},{"cell_type":"markdown","metadata":{"id":"Z6zo8cHCyUqB"},"source":["1. Using `GridSearchCV` try different parameters of kernel (`linear`, `rbf`, `sigmoid`), C (`0.01`, `0.1`, `1`, `1.5`, `5`, `10`), gamma (`scale`, `auto`), class_weight (`balanced`, `None`) use `random_state=21` and `probability=True` and get the best combination of them in terms of accuracy.\n","2. Create a dataframe from the results of the gridsearch and sort it ascendingly by the `rank_test_score`. Check if there is a huge difference between different combinations (sometimes a simpler model may give a comparable result)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dBiuP78ayUqB"},"outputs":[],"source":["svc = SVC(probability=True, random_state=21)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4NL1AfU0yUqC"},"outputs":[],"source":["param_grid = {'C': [0.01, 0.1, 1, 1.5, 5, 10],\n","              'kernel': ['linear', 'rbf', 'sigmoid'],\n","              'gamma': ['scale', 'auto'],\n","              'class_weight': ['balanced', None]\n","              }\n","\n","gs = GridSearchCV(svc, param_grid, scoring='accuracy', n_jobs=-1)\n","gs.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GoMznS9wyUqC"},"outputs":[],"source":["gs.best_params_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oaeHHckFyUqC"},"outputs":[],"source":["gs.best_score_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z_CDXonkyUqC"},"outputs":[],"source":["results = pd.DataFrame(gs.cv_results_)\n","results = results.sort_values('rank_test_score', ascending=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R4AwI3cbyUqC"},"outputs":[],"source":["results.head(7)"]},{"cell_type":"markdown","metadata":{"id":"a3w4FpldyUqC"},"source":["## 3. Decision tree"]},{"cell_type":"markdown","metadata":{"id":"ELqxX9sXyUqD"},"source":["1. Using `GridSearchCV` try different parameters of `max_depth` (from `1` to `49`), `class_weight` (`balanced`, `None`) and `criterion` (`entropy` and `gini`) and get the best combination of them in terms of accuracy. Use `random_state=21`.\n","2. Create a dataframe from the results of the gridsearch and sort it ascendingly by the `rank_test_score`, check if there is a huge difference between different combinations (sometimes a simpler model may give a comparable result)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q6YmUeUqyUqD"},"outputs":[],"source":["tree = DecisionTreeClassifier(random_state=21)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aF9K-bBGyUqD"},"outputs":[],"source":["param_grid = {'criterion': ['gini','entropy'],\n","              'max_depth': np.arange(1, 50),\n","              'class_weight': ['balanced', None]\n","            }\n","\n","gs = GridSearchCV(tree, param_grid, scoring='accuracy', n_jobs=-1)\n","gs.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7barDuTYyUqD"},"outputs":[],"source":["gs.best_params_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Txy-LhV5yUqD"},"outputs":[],"source":["gs.best_score_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IKBNKOqfyUqD"},"outputs":[],"source":["results = pd.DataFrame(gs.cv_results_)\n","results = results.sort_values('rank_test_score', ascending=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CHac1Ml0yUqE"},"outputs":[],"source":["results"]},{"cell_type":"markdown","metadata":{"id":"dLFxJKtiyUqE"},"source":["## 4. Random forest"]},{"cell_type":"markdown","metadata":{"id":"V6ADE7RuyUqE"},"source":["1. Using `GridSearchCV` try different parameters of `n_estimators` (`5`, `10`, `50`, `100`), `max_depth` (from `1` to `49`), `class_weight` (`balanced`, `None`) and `criterion` (`entropy` and `gini`) and get the best combination of them in terms of accuracy. Use random_state=21.\n","2. Create a dataframe from the results of the gridsearch and sort it ascendengly by the `rank_test_score`, check if there is a huge difference between different combinations (sometimes a simpler model may give a comparable result)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VOyEfEctyUqE"},"outputs":[],"source":["frt = RandomForestClassifier(random_state=21)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"otVWJ4CqyUqE"},"outputs":[],"source":["param_grid = {'n_estimators': [5, 10, 50, 100],\n","              'criterion': ['gini','entropy'],\n","              'max_depth': np.arange(1, 50),\n","              'class_weight': ['balanced', None],\n","              'random_state': [21]}\n","\n","gs = GridSearchCV(frt, param_grid, scoring='accuracy', n_jobs=-1)\n","gs.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y8CPm8gTyUqE"},"outputs":[],"source":["gs.best_params_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YuU50GSQyUqF"},"outputs":[],"source":["gs.best_score_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KkrTpWNoyUqF"},"outputs":[],"source":["results = pd.DataFrame(gs.cv_results_)\n","results = results.sort_values('rank_test_score', ascending=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wi2t0DNqyUqF"},"outputs":[],"source":["results"]},{"cell_type":"markdown","metadata":{"id":"WWa7ucWxyUqF"},"source":["## 5. Progress bar"]},{"cell_type":"markdown","metadata":{"id":"u2Q8KPBiyUqF"},"source":["Gridsearch can be a quite long process and you may find yourself wondering when it will end.\n","1. Create a manual gridsearch for the same parameters values of random forest iterating through the list of the possible values and calculating `cross_val_score` for each combination. Try to increase `n_jobs`. The value `cv` for `cross_val_score` is 5.\n","2. Track the progress using the library `tqdm.notebook`.\n","3. Create a dataframe from the results of the gridsearch with the columns corresponding to the names of the parameters and `mean_accuracy` and `std_accuracy`.\n","4. Sort it descendingly by the `mean_accuracy`, check if there is a huge difference between different combinations (sometimes a simpler model may give a comparable result)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a1x6AdqTyUqG"},"outputs":[],"source":["grid = list(ParameterGrid(param_grid))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UCBvyIm-yUqG"},"outputs":[],"source":["data = []\n","\n","for params in tqdm(grid):\n","    # print(params)\n","    # print(1)\n","    d = {}\n","    estimator = RandomForestClassifier(**params)\n","    sc = cross_val_score(estimator, X_train, y_train, cv=5, n_jobs=-1)\n","    # print(sc)\n","    d = {**params, 'mean_accuracy': np.mean(sc), 'std_accuracy': np.std(sc)}\n","    data.append(d)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pXNzb1QnyUqG"},"outputs":[],"source":["results_1 = pd.DataFrame(data)\n","results_1 = results_1.sort_values('mean_accuracy', ascending=False)\n","results_1"]},{"cell_type":"markdown","metadata":{"id":"SQMTOQynyUqG"},"source":["## 6. Predictions"]},{"cell_type":"markdown","metadata":{"id":"FF5VVXbGyUqG"},"source":["1. Choose the best model and use it to make predictions for the test dataset.\n","2. Calculate the final accuracy."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-vW7NVMOyUqG"},"outputs":[],"source":["rfc = RandomForestClassifier(n_estimators=50, max_depth=28, criterion='gini', class_weight=None, random_state=21)\n","rfc.fit(X_train, y_train)\n","y_pred = rfc.predict(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qO--d7bmyUqG"},"outputs":[],"source":["accuracy_score(y_test, y_pred)"]}],"metadata":{"colab":{"name":"01_gridsearch.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"nbformat":4,"nbformat_minor":0}
